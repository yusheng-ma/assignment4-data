import os
import gzip
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import requests
import threading

# è¨­å®š
WET_PATHS_FILE = "wet.paths.gz"        # ä½ çš„æœ¬æ©Ÿ .gz æª”
OUTPUT_DIR = "wet_files"               # ä¸‹è¼‰ç›®æ¨™è³‡æ–™å¤¾
TARGET_COUNT = 5000                     # éœ€è¦ 100 å€‹æˆåŠŸä¸‹è¼‰çš„ WET æª”
MAX_THREADS = 8                        # åŒæ™‚ä¸‹è¼‰æ•¸é‡
CHUNK_SIZE = 1024 * 1024               # æ¯æ¬¡ä¸‹è¼‰å¤§å°ï¼ˆ1MBï¼‰

os.makedirs(OUTPUT_DIR, exist_ok=True)

# å·²å­˜åœ¨çš„æª”æ¡ˆ
downloaded_files = set(os.listdir(OUTPUT_DIR))
success_count = len(downloaded_files)
print(f"ğŸ“¦ å·²å­˜åœ¨ {success_count} å€‹æª”æ¡ˆã€‚ç›®æ¨™ï¼š{TARGET_COUNT} å€‹")

# å…±äº«è®Šæ•¸èˆ‡é–
stop_flag = threading.Event()
lock = threading.Lock()

def download_file(path):
    if stop_flag.is_set():
        return False

    url = f"https://data.commoncrawl.org/{path}"
    filename = os.path.join(OUTPUT_DIR, os.path.basename(path))
    temp_file = filename + ".part"

    if os.path.basename(filename) in downloaded_files:
        return True  # å·²å­˜åœ¨

    try:
        headers = {}
        if os.path.exists(temp_file):
            downloaded_size = os.path.getsize(temp_file)
            headers["Range"] = f"bytes={downloaded_size}-"
        else:
            downloaded_size = 0

        with requests.get(url, headers=headers, stream=True, timeout=30) as r:
            if r.status_code not in (200, 206):
                print(f"\nâŒ HTTP Error {r.status_code} for {url}")
                return False

            with open(temp_file, "ab") as f:
                for chunk in r.iter_content(chunk_size=CHUNK_SIZE):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)

            os.rename(temp_file, filename)
            with lock:
                downloaded_files.add(os.path.basename(filename))
                global success_count
                success_count += 1
                if success_count >= TARGET_COUNT:
                    stop_flag.set()  # è§¸ç™¼åœæ­¢ä¿¡è™Ÿ
            return True

    except Exception as e:
        print(f"\nâŒ Error downloading {url}: {e}")
        return False

def generate_paths():
    """å¾æœ¬æ©Ÿçš„ wet.paths.gz è®€å–æ¯ä¸€è¡Œ"""
    with gzip.open(WET_PATHS_FILE, "rt", encoding="utf-8") as f:
        for line in f:
            yield line.strip()

def main():
    global success_count

    remaining = max(TARGET_COUNT - success_count, 0)
    print(f"â³ é‚„éœ€è¦ä¸‹è¼‰ {remaining} å€‹æª”æ¡ˆ")

    with tqdm(total=remaining, desc="Downloading") as pbar:
        with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
            futures = []

            for path in generate_paths():
                if stop_flag.is_set():
                    break
                futures.append(executor.submit(download_file, path))

            completed = 0
            for future in as_completed(futures):
                result = future.result()
                if result:
                    completed += 1
                    pbar.update(1)
                if stop_flag.is_set():
                    break

        print(f"\nâœ… æˆåŠŸä¸‹è¼‰ {min(success_count, TARGET_COUNT)} å€‹ WET æ–‡ä»¶")

if __name__ == "__main__":
    main()